model:
  hidden_size: 256
  layer_num: 2
  head_num: 2
  dropout_rate: 0.5
  activation: 'gelu'
  layer_norm_eps: 1e-12

train:
  negative_count: 1
  init_method: normal
