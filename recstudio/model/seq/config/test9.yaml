model:
  hidden_size: 256
  layer_num: 2
  head_num: 2
  dropout_rate: 0.5
  activation: 'gelu'
  layer_norm_eps: 1e-12
  # Graph contrastive
  k: 2
  gnn_layers: 2
  noise: 0.1
  temperature: 0.2
  gcl_weight: 0.1
  cl_weight: 0.1
  kl_weight: 0.01
  augment_type: item_random # item_crop, item_mask, item_reorder, item_random

train:
  batch_size: 256
  negative_count: 1
  init_method: normal
